#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Hockey Prediction System - Elo Rating Model (ENHANCED MIGRATED)
================================================================
Implementuje dynamick√Ω Elo rating syst√©m pro NHL t√Ωmy.
Upraveno pro franchise-based datab√°zov√© sch√©ma s tr√©nink/backtesting rozdƒõlen√≠m.

MIGRACE: Enhanced infrastructure s per-component logging, performance monitoring,
safe file handling a robust error handling.

Um√≠stƒõn√≠: src/models/elo_rating_model.py
"""

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sqlalchemy.exc import SQLAlchemyError, OperationalError, DisconnectionError
from datetime import datetime, date
from typing import Dict, Tuple, List, Optional
import json
import time
import traceback

# === MIGRACE: Enhanced infrastructure imports ===
from config.paths import PATHS
from config.settings import settings
from config.logging_config import (
    setup_logging, get_component_logger, PerformanceLogger,
    LoggingConfig
)
from src.utils.file_handlers import (
    save_model_safe, load_model_safe, write_json, read_json,
    save_processed_data
)

# === MIGRACE: Component-specific logger pro models ===
logger = get_component_logger(__name__, 'models')


class DatabaseConnectionManager:
    """Enhanced database connection s retry logic a error handling"""
    
    def __init__(self, connection_string: str, max_retries: int = 3, retry_delay: float = 1.0):
        self.connection_string = connection_string
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self._engine = None
    
    @property
    def engine(self):
        """Lazy connection s retry logic"""
        if self._engine is None:
            self._connect_with_retry()
        return self._engine
    
    def _connect_with_retry(self):
        """Pokus o p≈ôipojen√≠ s retry logic"""
        for attempt in range(self.max_retries):
            try:
                logger.info(f"Database connection attempt {attempt + 1}/{self.max_retries}")
                self._engine = create_engine(
                    self.connection_string,
                    pool_pre_ping=True,  # Test connections before use
                    pool_recycle=3600,   # Recycle connections every hour
                    connect_args={"connect_timeout": 30}
                )
                # Test connection
                with self._engine.connect() as conn:
                    from sqlalchemy import text
                    conn.execute(text("SELECT 1"))
                logger.info("Database connection established successfully")
                return
                
            except Exception as e:
                logger.error(f"Database connection attempt {attempt + 1} failed: {e}")
                if attempt < self.max_retries - 1:
                    logger.info(f"Retrying in {self.retry_delay} seconds...")
                    time.sleep(self.retry_delay)
                    self.retry_delay *= 1.5  # Exponential backoff
                else:
                    logger.error("All database connection attempts failed")
                    raise
    
    def execute_query_safe(self, query: str, description: str = "Query") -> pd.DataFrame:
        """Safe query execution s retry logic a performance monitoring"""
        for attempt in range(self.max_retries):
            try:
                start_time = time.time()
                logger.debug(f"Executing {description}")
                
                df = pd.read_sql(query, self.engine)
                
                execution_time = time.time() - start_time
                                
                # Smart logging: INFO for important/slow queries, DEBUG for routine ones
                if execution_time > 0.5 or len(df) > 1000 or 'historical' in description.lower():
                    logger.info(f"{description} completed: {len(df)} rows in {execution_time:.2f}s")
                else:
                    logger.debug(f"{description} completed: {len(df)} rows in {execution_time:.3f}s")
                
                return df
                
            except (OperationalError, DisconnectionError) as e:
                logger.warning(f"{description} failed (attempt {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    logger.info("Reconnecting to database...")
                    self._engine = None  # Force reconnection
                    time.sleep(self.retry_delay)
                else:
                    logger.error(f"{description} failed after {self.max_retries} attempts")
                    raise
            except Exception as e:
                logger.error(f"{description} failed with unexpected error: {e}")
                LoggingConfig.log_exception(logger, e, description)
                raise


class EloRatingSystem:
    """
    Enhanced Elo Rating System pro NHL t√Ωm predikce
    MIGRACE: Aktualizov√°no s enhanced infrastructure
    """
    
    def __init__(self, 
                 initial_rating: Optional[float] = None,
                 k_factor: Optional[float] = None,
                 home_advantage: Optional[float] = None,
                 season_regression: Optional[float] = None):
        """
        Inicializace Enhanced Elo Rating Syst√©mu
        
        Args:
            initial_rating: V√Ωchoz√≠ Elo rating pro v≈°echny t√Ωmy (z settings pokud None)
            k_factor: Learning rate - vy≈°≈°√≠ = volatilnƒõj≈°√≠ (z settings pokud None)
            home_advantage: Bonus pro dom√°c√≠ t√Ωm (z settings pokud None)
            season_regression: Regrese rating≈Ø mezi sez√≥nami 0-1 (z settings pokud None)
        """
        # Naƒçti parametry ze settings nebo pou≈æij zadan√©
        self.initial_rating = initial_rating or settings.model.elo_initial_rating
        self.k_factor = k_factor or settings.model.elo_k_factor
        self.home_advantage = home_advantage or settings.model.elo_home_advantage
        self.season_regression = season_regression or settings.model.elo_season_regression
        
        # √ölo≈æi≈°tƒõ team rating≈Ø
        self.team_ratings = {}  # {team_id: current_rating}
        self.rating_history = []  # Historick√© ratings pro anal√Ωzu
        
        # === MIGRACE: Enhanced database connection manager ===
        self.db_manager = DatabaseConnectionManager(
            settings.database.connection_string,
            max_retries=3,
            retry_delay=1.0
        )
        
        # === MIGRACE: Performance monitoring ===
        self.perf_logger = PerformanceLogger(logger)
        
        # Tracking v√Ωkonu
        self.predictions = []
        self.results = []
        
        logger.info("Enhanced Elo Rating System inicializov√°n:")
        logger.info(f"  Initial rating: {self.initial_rating}")
        logger.info(f"  K-factor: {self.k_factor}")
        logger.info(f"  Home advantage: {self.home_advantage}")
        logger.info(f"  Season regression: {self.season_regression}")
    
    def expected_score(self, rating_a: float, rating_b: float, home_advantage: float = 0) -> float:
        """
        Vypoƒç√≠t√° oƒçek√°van√© sk√≥re pro t√Ωm A proti t√Ωmu B
        
        Args:
            rating_a: Elo rating t√Ωmu A
            rating_b: Elo rating t√Ωmu B
            home_advantage: Dodateƒçn√Ω rating pro dom√°c√≠ t√Ωm
            
        Returns:
            Oƒçek√°van√° pravdƒõpodobnost v√Ωhry t√Ωmu A (0-1)
        """
        adjusted_rating_a = rating_a + home_advantage
        rating_diff = adjusted_rating_a - rating_b
        
        # Standardn√≠ Elo formule
        expected = 1 / (1 + 10 ** (-rating_diff / 400))
        return expected
    
    def update_ratings(self, team_a_id: int, team_b_id: int, actual_score: float, 
                      home_advantage: float = 0, k_multiplier: float = 1.0) -> Tuple[float, float]:
        """
        Aktualizuje Elo ratings po z√°pase
        
        Args:
            team_a_id: ID dom√°c√≠ho t√Ωmu
            team_b_id: ID hostuj√≠c√≠ho t√Ωmu
            actual_score: 1 pokud t√Ωm A vyhr√°l, 0 pokud t√Ωm B vyhr√°l, 0.5 pro OT/SO por√°≈æku
            home_advantage: Bonus pro dom√°c√≠ v√Ωhodu
            k_multiplier: N√°sobitel pro K-factor (pro playoff z√°pasy, atd.)
            
        Returns:
            Tuple (new_rating_a, new_rating_b)
        """
        # Z√≠skej aktu√°ln√≠ ratings
        rating_a = self.team_ratings.get(team_a_id, self.initial_rating)
        rating_b = self.team_ratings.get(team_b_id, self.initial_rating)
        
        # Vypoƒç√≠taj oƒçek√°van√© sk√≥re
        expected_a = self.expected_score(rating_a, rating_b, home_advantage)
        expected_b = 1 - expected_a
        
        # Vypoƒç√≠taj zmƒõny ratingu
        k_factor = self.k_factor * k_multiplier
        change_a = k_factor * (actual_score - expected_a)
        change_b = k_factor * ((1 - actual_score) - expected_b)
        
        # Aktualizuj ratings
        new_rating_a = rating_a + change_a
        new_rating_b = rating_b + change_b
        
        self.team_ratings[team_a_id] = new_rating_a
        self.team_ratings[team_b_id] = new_rating_b
        
        return new_rating_a, new_rating_b
    
    def game_result_to_score(self, home_score: int, away_score: int, 
                           overtime_shootout: str = '') -> Tuple[float, str]:
        """
        P≈ôevede v√Ωsledek z√°pasu na Elo sk√≥re form√°t
        
        Args:
            home_score: Fin√°ln√≠ sk√≥re dom√°c√≠ho t√Ωmu
            away_score: Fin√°ln√≠ sk√≥re hostuj√≠c√≠ho t√Ωmu
            overtime_shootout: 'OT', 'SO', nebo pr√°zdn√Ω string
            
        Returns:
            Tuple (home_team_score, result_type)
            home_team_score: 1.0 v√Ωhra, 0.0 por√°≈æka, 0.6 OT/SO v√Ωhra, 0.4 OT/SO por√°≈æka
        """
        if home_score > away_score:
            if overtime_shootout in ['OT', 'SO']:
                return 0.6, f'HOME_WIN_{overtime_shootout}'  # OT/SO v√Ωhra m√©nƒõ cenn√°
            else:
                return 1.0, 'HOME_WIN_REG'  # Regul√©rn√≠ v√Ωhra
        elif away_score > home_score:
            if overtime_shootout in ['OT', 'SO']:
                return 0.4, f'AWAY_WIN_{overtime_shootout}'  # OT/SO por√°≈æka dostane body
            else:
                return 0.0, 'AWAY_WIN_REG'  # Regul√©rn√≠ por√°≈æka
        else:
            return 0.5, 'TIE'  # Nemƒõlo by se st√°t v modern√≠ NHL
    
    def load_historical_games(self, season_start: str = '2022', season_end: str = '2024') -> pd.DataFrame:
        """
        Naƒçte historick√© z√°pasy z datab√°ze pro tr√©nov√°n√≠
        KRITICK√â: Naƒç√≠t√° pouze data do sez√≥ny 2023/24 (vƒçetnƒõ)
        Data z 2024/25 jsou rezervov√°na pro backtesting!
        
        Args:
            season_start: Prvn√≠ sez√≥na k zahrnut√≠ (nap≈ô. '2022')
            season_end: Posledn√≠ sez√≥na pro tr√©nov√°n√≠ (default '2024' = sez√≥na 2023/24)
            
        Returns:
            DataFrame s v√Ωsledky z√°pas≈Ø pro tr√©nov√°n√≠
        """
        query = f"""
        SELECT 
            g.id,
            g.date,
            g.datetime_et,
            g.season,
            g.home_team_id,
            g.away_team_id,
            g.home_score,
            g.away_score,
            g.overtime_shootout,
            
            -- Dom√°c√≠ t√Ωm s franchise info
            ht.name as home_team_name,
            hf.franchise_name as home_franchise_name,
            
            -- Hostuj√≠c√≠ t√Ωm s franchise info  
            at.name as away_team_name,
            af.franchise_name as away_franchise_name
            
        FROM games g
        JOIN teams ht ON g.home_team_id = ht.id
        JOIN franchises hf ON ht.franchise_id = hf.id
        JOIN teams at ON g.away_team_id = at.id  
        JOIN franchises af ON at.franchise_id = af.id
        
        WHERE g.status = 'completed'
            AND g.season >= '{season_start}'
            AND g.season <= '{season_end}'  -- KRITICK√â: Excluded 2024/25 from training!
            AND g.home_score IS NOT NULL 
            AND g.away_score IS NOT NULL
        ORDER BY g.date, g.id
        """
        
        # === MIGRACE: Safe database query s performance monitoring ===
        try:
            self.perf_logger.start_timer('load_historical_games')
            
            df = self.db_manager.execute_query_safe(
                query, 
                f"Loading historical games ({season_start}-{season_end})"
            )
            
            self.perf_logger.end_timer('load_historical_games')
            
            logger.info(f"Naƒçteno {len(df)} dokonƒçen√Ωch z√°pas≈Ø pro TR√âNOV√ÅN√ç z {season_start} do {season_end}")
            logger.info("D≈ÆLE≈ΩIT√â: Sez√≥na 2024/25 vylouƒçena - rezervov√°na pro backtesting!")
            
            return df
            
        except Exception as e:
            logger.error("Failed to load historical games data")
            LoggingConfig.log_exception(logger, e, "load_historical_games")
            raise
    
    def train_on_historical_data(self, games_df: pd.DataFrame, 
                            evaluate_predictions: bool = True) -> Dict:
        """
        Tr√©nuje Elo ratings na historick√Ωch datech z√°pas≈Ø
        KRITICK√â: Pou≈æ√≠v√° pouze data do sez√≥ny 2023/24!
        Data z 2024/25 jsou rezervov√°na pro backtesting.
        """
        # === MIGRACE: Enhanced validation s better error messages ===
        logger.info("Tr√©nov√°n√≠ Elo ratings na historick√Ωch datech...")
        if not games_df.empty:
            max_season = games_df['season'].max()
            
            # Convert to int for comparison (handle both string and int season formats)
            try:
                max_season_int = int(max_season)
                if max_season_int > 2024:
                    raise ValueError(f"KRITICK√â: Tr√©novac√≠ data obsahuj√≠ sez√≥nu {max_season}!")
            except (ValueError, TypeError):
                if str(max_season) > '2024':
                    raise ValueError(f"KRITICK√â: Tr√©novac√≠ data obsahuj√≠ sez√≥nu {max_season}!")
        
        logger.info("Tr√©nov√°n√≠ Elo ratings na historick√Ωch datech s franchise podporou...")
        logger.info(f"Tr√©novac√≠ data: sez√≥ny {games_df['season'].min()} do {games_df['season'].max()}")
        logger.info("POTVRZENO: Sez√≥na 2024/25 vylouƒçena z tr√©ninku")
        
        # === MIGRACE: Performance monitoring pro training ===
        self.perf_logger.start_timer('elo_training')
        
        try:
            # Debug sample team IDs from data
            sample_teams = set(list(games_df['home_team_id'].unique())[:5])
            logger.debug(f"Uk√°zkov√© team ID z dat z√°pas≈Ø: {sample_teams}")

            # Inicializuj v≈°echny t√Ωmy se z√°kladn√≠m ratingem - ZJEDNODU≈†ENO
            unique_teams = set(games_df['home_team_id'].unique()) | set(games_df['away_team_id'].unique())
            for team_id in unique_teams:
                self.team_ratings[team_id] = self.initial_rating
            
            logger.info(f"Inicializov√°no {len(unique_teams)} t√Ωm≈Ø s ratingem {self.initial_rating}")
            
            # Track for evaluation
            predictions = []
            actuals = []
            current_season = None
            games_processed = 0
            
            # === MIGRACE: Progress monitoring ===
            total_games = len(games_df)
            progress_interval = max(100, total_games // 20)  # Show progress every 5%
            
            # Zpracuj z√°pasy chronologicky
            for idx, game in games_df.iterrows():
                home_team_id = game['home_team_id']
                away_team_id = game['away_team_id']
                
                # Aplikuj sez√≥nn√≠ regresi pokud nov√° sez√≥na
                if current_season != game['season']:
                    if current_season is not None:
                        self._apply_season_regression()
                        logger.info(f"Aplikov√°na sez√≥nn√≠ regrese pro sez√≥nu {game['season']}")
                    current_season = game['season']
                
                # Udƒõlej predikci p≈ôed aktualizac√≠ rating≈Ø
                if evaluate_predictions:
                    home_rating = self.team_ratings.get(home_team_id, self.initial_rating)
                    away_rating = self.team_ratings.get(away_team_id, self.initial_rating)
                    predicted_prob = self.expected_score(home_rating, away_rating, self.home_advantage)
                    predictions.append(predicted_prob)
                
                # Z√≠skej skuteƒçn√Ω v√Ωsledek
                home_score, result_type = self.game_result_to_score(
                    game['home_score'], 
                    game['away_score'],
                    game['overtime_shootout']
                )
                
                if evaluate_predictions:
                    actuals.append(home_score if home_score in [0.0, 1.0] else int(home_score > 0.5))
                
                # Aktualizuj ratings
                old_home_rating = self.team_ratings.get(home_team_id, self.initial_rating)
                old_away_rating = self.team_ratings.get(away_team_id, self.initial_rating)
                
                new_home_rating, new_away_rating = self.update_ratings(
                    home_team_id, away_team_id, home_score, self.home_advantage
                )
                
                # Ulo≈æ rating history
                self.rating_history.append({
                    'game_id': game['id'],
                    'date': game['date'],
                    'season': game['season'],
                    'home_team_id': home_team_id,
                    'away_team_id': away_team_id,
                    'home_rating_before': old_home_rating,
                    'away_rating_before': old_away_rating,
                    'home_rating_after': new_home_rating,
                    'away_rating_after': new_away_rating,
                    'actual_result': home_score,
                    'result_type': result_type
                })
                
                games_processed += 1
                
                # === MIGRACE: Progress logging ===
                if games_processed % progress_interval == 0:
                    progress = (games_processed / total_games) * 100
                    logger.info(f"Training progress: {games_processed}/{total_games} games ({progress:.1f}%)")
            
            self.perf_logger.end_timer('elo_training')
            
            # Vypoƒç√≠tej evaluation metrics
            metrics = {}
            if evaluate_predictions and predictions:
                self.perf_logger.start_timer('metrics_calculation')
                metrics = self._calculate_metrics(predictions, actuals)
                self.perf_logger.end_timer('metrics_calculation')
                logger.info(f"Tr√©nov√°n√≠ dokonƒçeno. P≈ôesnost: {metrics.get('accuracy', 0):.3f}")
            
            # Z√≠skej fin√°ln√≠ team ratings
            team_ratings_df = self.get_current_ratings()
            
            return {
                'metrics': metrics,
                'team_ratings': team_ratings_df,
                'games_processed': games_processed,
                'rating_history': self.rating_history[-10:]  # Posledn√≠ch 10 pro kontrolu
            }
            
        except Exception as e:
            self.perf_logger.end_timer('elo_training')  # Ensure timer is stopped
            logger.error("Training failed")
            LoggingConfig.log_exception(logger, e, "train_on_historical_data")
            raise
    
    def _apply_season_regression(self):
        """Aplikuje regresi k pr≈Ømƒõru mezi sez√≥nami"""
        if not self.team_ratings:
            logger.warning("No team ratings to apply regression to")
            return
            
        mean_rating = np.mean(list(self.team_ratings.values()))
        regressed_count = 0
        
        for team_id in self.team_ratings:
            current_rating = self.team_ratings[team_id]
            regressed_rating = current_rating + self.season_regression * (mean_rating - current_rating)
            self.team_ratings[team_id] = regressed_rating
            regressed_count += 1
        
        logger.debug(f"Applied season regression to {regressed_count} teams (mean: {mean_rating:.1f})")
    
    def predict_game(self, home_team_id: int, away_team_id: int) -> Dict:
        """
        P≈ôedpov√≠d√° v√Ωsledek jednoho z√°pasu
        
        Args:
            home_team_id: ID dom√°c√≠ho t√Ωmu
            away_team_id: ID hostuj√≠c√≠ho t√Ωmu
            
        Returns:
            Dictionary s detaily predikce
        """
        try:
            home_rating = self.team_ratings.get(home_team_id, self.initial_rating)
            away_rating = self.team_ratings.get(away_team_id, self.initial_rating)
            
            home_win_prob = self.expected_score(home_rating, away_rating, self.home_advantage)
            away_win_prob = 1 - home_win_prob
            
            # Z√≠skej jm√©na t√Ωm≈Ø
            team_names = self._get_team_names([home_team_id, away_team_id])
            
            prediction = {
                'home_team_id': home_team_id,
                'away_team_id': away_team_id,
                'home_team_name': team_names.get(home_team_id, f'Team_{home_team_id}'),
                'away_team_name': team_names.get(away_team_id, f'Team_{away_team_id}'),
                'home_rating': home_rating,
                'away_rating': away_rating, 
                'home_win_probability': home_win_prob,
                'away_win_probability': away_win_prob,
                'predicted_winner': 'HOME' if home_win_prob > 0.5 else 'AWAY',
                'confidence': abs(home_win_prob - 0.5) * 2,  # 0-1 ≈°k√°la
                'rating_difference': home_rating - away_rating + self.home_advantage
            }
            
            logger.debug(f"Game prediction: {prediction['home_team_name']} vs {prediction['away_team_name']} -> {prediction['predicted_winner']} ({prediction['confidence']:.2f})")
            
            return prediction
            
        except Exception as e:
            logger.error(f"Failed to predict game {home_team_id} vs {away_team_id}")
            LoggingConfig.log_exception(logger, e, "predict_game")
            raise
    
    def predict_upcoming_games(self, days_ahead: int = 7) -> List[Dict]:
        """
        P≈ôedpov√≠d√° v√Ωsledky nadch√°zej√≠c√≠ch z√°pas≈Ø
        Aktualizov√°no pro franchise-based sch√©ma
        
        Args:
            days_ahead: Poƒçet dn√≠ dop≈ôedu pro predikce
            
        Returns:
            Seznam prediction dictionary
        """
        query = f"""
        SELECT 
            g.id,
            g.date,
            g.datetime_et,
            g.home_team_id,
            g.away_team_id,
            
            -- Aktu√°ln√≠ jm√©na t√Ωm≈Ø (is_current = TRUE)
            ht.name as home_team_name,
            at.name as away_team_name,
            
            -- Franchise info pro kontext
            hf.franchise_name as home_franchise,
            af.franchise_name as away_franchise
            
        FROM games g
        JOIN teams ht ON g.home_team_id = ht.id AND ht.is_current = TRUE
        JOIN franchises hf ON ht.franchise_id = hf.id
        JOIN teams at ON g.away_team_id = at.id AND at.is_current = TRUE
        JOIN franchises af ON at.franchise_id = af.id
        
        WHERE g.status = 'scheduled'
            AND g.date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '{days_ahead} days'
        ORDER BY g.date, g.datetime_et
        """
        
        try:
            self.perf_logger.start_timer('predict_upcoming_games')
            
            upcoming_games = self.db_manager.execute_query_safe(
                query, 
                f"Loading upcoming games ({days_ahead} days ahead)"
            )
            
            predictions = []
            for _, game in upcoming_games.iterrows():
                try:
                    prediction = self.predict_game(game['home_team_id'], game['away_team_id'])
                    prediction['game_id'] = game['id']
                    prediction['game_date'] = game['date']
                    prediction['game_datetime'] = game['datetime_et']
                    prediction['home_franchise'] = game['home_franchise']
                    prediction['away_franchise'] = game['away_franchise']
                    predictions.append(prediction)
                except Exception as e:
                    logger.warning(f"Failed to predict game {game['id']}: {e}")
                    continue
            
            self.perf_logger.end_timer('predict_upcoming_games')
            
            logger.info(f"Vygenerov√°ny predikce pro {len(predictions)} nadch√°zej√≠c√≠ch z√°pas≈Ø")
            return predictions
            
        except Exception as e:
            logger.error("Failed to predict upcoming games")
            LoggingConfig.log_exception(logger, e, "predict_upcoming_games")
            raise
    
    def get_current_ratings(self) -> pd.DataFrame:
        """
        Z√≠sk√° aktu√°ln√≠ team ratings jako DataFrame
        """
        if not self.team_ratings:
            logger.warning("No team ratings available")
            return pd.DataFrame()
        
        logger.debug("Z√≠sk√°v√°n√≠ aktu√°ln√≠ch rating≈Ø...")
        
        try:
            # Z√≠skej pouze validn√≠ team IDs
            team_ids = [tid for tid in self.team_ratings.keys() 
                if isinstance(tid, (int, np.integer)) and not isinstance(tid, str)]
            logger.debug(f"Z√≠sk√°v√°n√≠ jmen pro {len(team_ids)} t√Ωm≈Ø...")
            
            team_names = self._get_team_names(team_ids)
            logger.debug(f"Z√≠sk√°no {len(team_names)} jmen t√Ωm≈Ø")
            
            ratings_data = []
            for team_id, rating in self.team_ratings.items():
                # P≈ôeskoƒç historick√© ratings
                if isinstance(team_id, str) and 'historical' in str(team_id):
                    continue
                    
                team_name = team_names.get(team_id, f'Team_{team_id}')
                ratings_data.append({
                    'team_id': team_id,
                    'team_name': team_name,
                    'elo_rating': rating,
                    'rating_rank': 0
                })
            
            df = pd.DataFrame(ratings_data)
            if not df.empty:
                df = df.sort_values('elo_rating', ascending=False).reset_index(drop=True)
                df['rating_rank'] = range(1, len(df) + 1)
            
            logger.debug(f"Successfully created ratings DataFrame with {len(df)} teams")
            return df
            
        except Exception as e:
            logger.error("Failed to get current ratings")
            LoggingConfig.log_exception(logger, e, "get_current_ratings")
            return pd.DataFrame()
    
    def _get_team_names(self, team_ids: List[int]) -> Dict[int, str]:
        """
        Z√≠sk√° jm√©na t√Ωm≈Ø pro dan√© team ID s enhanced error handling
        """
        logger.debug(f"_get_team_names vol√°no s {len(team_ids)} ID")
        
        if not team_ids:
            return {}
        
        try:
            # Validn√≠ team IDs
            valid_team_ids = [int(tid) for tid in team_ids 
                      if isinstance(tid, (int, np.integer))]
            if not valid_team_ids:
                logger.warning("Nenalezena ≈æ√°dn√° validn√≠ integer team ID")
                return {}
            
            logger.debug(f"Validn√≠ team ID: {valid_team_ids[:5]}...")
            
            # Jednoduch√Ω dotaz - z√≠skej aktu√°ln√≠ t√Ωmy
            if len(valid_team_ids) == 1:
                query = f"""
                SELECT t.id, t.name, f.franchise_name
                FROM teams t
                JOIN franchises f ON t.franchise_id = f.id
                WHERE t.id = {valid_team_ids[0]} AND t.is_current = TRUE
                """
            else:
                team_ids_str = ','.join(map(str, valid_team_ids))
                query = f"""
                SELECT t.id, t.name, f.franchise_name
                FROM teams t
                JOIN franchises f ON t.franchise_id = f.id
                WHERE t.id IN ({team_ids_str}) AND t.is_current = TRUE
                """
            
            logger.debug("Prov√°dƒõn√≠ SQL dotazu...")
            df = self.db_manager.execute_query_safe(
                query, 
                f"Getting team names for {len(valid_team_ids)} teams"
            )
            logger.debug(f"Dotaz vr√°til {len(df)} ≈ô√°dk≈Ø")
            
            if df.empty:
                logger.warning("Dotaz nevr√°til ≈æ√°dn√© v√Ωsledky - t√Ωmy mo≈æn√° nejsou aktu√°ln√≠")
                # Zkus bez is_current filtru
                query_fallback = query.replace(" AND t.is_current = TRUE", "")
                df = self.db_manager.execute_query_safe(
                    query_fallback,
                    "Getting team names (fallback without is_current filter)"
                )
                logger.debug(f"Fallback dotaz vr√°til {len(df)} ≈ô√°dk≈Ø")
            
            result = dict(zip(df['id'], df['name']))
            logger.debug(f"√öspƒõ≈°nƒõ zmapov√°no {len(result)} jmen t√Ωm≈Ø")
            return result
            
        except Exception as e:
            logger.error("Failed to get team names")
            LoggingConfig.log_exception(logger, e, "_get_team_names")
            # Vra≈• fallback
            return {int(tid): f'Team_{tid}' for tid in team_ids if isinstance(tid, (int, np.integer))}
    
    def _calculate_metrics(self, predictions: List[float], actuals: List[int]) -> Dict:
        """Vypoƒç√≠t√° metriky predikce s enhanced error handling"""
        try:
            predictions = np.array(predictions)
            actuals = np.array(actuals)
            
            if len(predictions) != len(actuals):
                logger.warning(f"Mismatch in predictions ({len(predictions)}) vs actuals ({len(actuals)})")
                return {}
            
            # P≈ôeveƒè pravdƒõpodobnosti na bin√°rn√≠ predikce
            binary_predictions = (predictions > 0.5).astype(int)
            
            # P≈ôesnost
            accuracy = np.mean(binary_predictions == actuals)
            
            # Brier Score (ni≈æ≈°√≠ je lep≈°√≠)
            brier_score = np.mean((predictions - actuals) ** 2)
            
            # Log Loss 
            epsilon = 1e-15  # Zabra≈à log(0)
            predictions_clipped = np.clip(predictions, epsilon, 1 - epsilon)
            log_loss = -np.mean(actuals * np.log(predictions_clipped) + 
                               (1 - actuals) * np.log(1 - predictions_clipped))
            
            metrics = {
                'accuracy': accuracy,
                'brier_score': brier_score,
                'log_loss': log_loss,
                'total_predictions': len(predictions)
            }
            
            logger.debug(f"Calculated metrics: accuracy={accuracy:.3f}, brier_score={brier_score:.3f}")
            return metrics
            
        except Exception as e:
            logger.error("Failed to calculate metrics")
            LoggingConfig.log_exception(logger, e, "_calculate_metrics")
            return {}

    def load_backtesting_games(self, season: str = '2025') -> pd.DataFrame:
        """
        Naƒçte z√°pasy pro backtesting (sez√≥na 2024/25)
        KRITICK√â: Tato data NESM√ç b√Ωt pou≈æita pro tr√©nning!
        
        Args:
            season: Sez√≥na pro backtesting (default '2025' = sez√≥na 2024/25)
            
        Returns:
            DataFrame se z√°pasy pro backtesting (vƒçetnƒõ napl√°novan√Ωch z√°pas≈Ø)
        """
        query = f"""
        SELECT 
            g.id,
            g.date,
            g.datetime_et,
            g.season,
            g.home_team_id,
            g.away_team_id,
            g.home_score,
            g.away_score,
            g.overtime_shootout,
            g.status,
            
            -- Aktu√°ln√≠ jm√©na t√Ωm≈Ø (z franchise perspektivy)
            ht.name as home_team_name,
            hf.franchise_name as home_franchise_name,
            
            -- Hostuj√≠c√≠ t√Ωm s franchise info  
            at.name as away_team_name,
            af.franchise_name as away_franchise_name
            
        FROM games g
        JOIN teams ht ON g.home_team_id = ht.id
        JOIN franchises hf ON ht.franchise_id = hf.id
        JOIN teams at ON g.away_team_id = at.id  
        JOIN franchises af ON at.franchise_id = af.id
        
        WHERE g.season = '{season}'
            -- Zahrnout dokonƒçen√© I napl√°novan√© z√°pasy pro backtesting
        ORDER BY g.date, g.datetime_et, g.id
        """
        
        try:
            self.perf_logger.start_timer('load_backtesting_games')
            
            df = self.db_manager.execute_query_safe(
                query,
                f"Loading backtesting games (season {season})"
            )
            
            self.perf_logger.end_timer('load_backtesting_games')
            
            completed_games = len(df[df['status'] == 'completed'])
            scheduled_games = len(df[df['status'] == 'scheduled'])
            
            logger.info(f"Naƒçteno {len(df)} z√°pas≈Ø pro BACKTESTING ze sez√≥ny {season}")
            logger.info(f"  - Dokonƒçen√©: {completed_games} z√°pas≈Ø")
            logger.info(f"  - Napl√°novan√©: {scheduled_games} z√°pas≈Ø")
            logger.warning("P≈òIPOM√çNKA: Tyto z√°pasy nebyly pou≈æity pro tr√©nov√°n√≠ modelu!")
            
            return df
            
        except Exception as e:
            logger.error(f"Failed to load backtesting games for season {season}")
            LoggingConfig.log_exception(logger, e, "load_backtesting_games")
            raise

    def get_data_split_summary(self) -> Dict:
        """
        Poskytne p≈ôehled rozdƒõlen√≠ dat pro tr√©nov√°n√≠ vs backtesting
        """
        try:
            self.perf_logger.start_timer('data_split_summary')
            
            training_query = """
            SELECT season, COUNT(*) as game_count, 'TRAINING' as dataset_type
            FROM games 
            WHERE status = 'completed' AND season <= '2024'
            GROUP BY season
            """
            
            backtesting_query = """
            SELECT season, COUNT(*) as game_count, 'BACKTESTING' as dataset_type
            FROM games 
            WHERE season = '2025'
            GROUP BY season
            """
            
            training_df = self.db_manager.execute_query_safe(
                training_query, "Getting training data summary"
            )
            backtesting_df = self.db_manager.execute_query_safe(
                backtesting_query, "Getting backtesting data summary"
            )
            
            combined_df = pd.concat([training_df, backtesting_df], ignore_index=True)
            
            summary = {
                'training_seasons': training_df['season'].tolist(),
                'training_games': int(training_df['game_count'].sum()),
                'backtesting_season': '2025',
                'backtesting_games': int(backtesting_df['game_count'].sum()) if not backtesting_df.empty else 0,
                'data_split': combined_df.to_dict('records')
            }
            
            self.perf_logger.end_timer('data_split_summary')
            
            return summary
            
        except Exception as e:
            logger.error("Failed to get data split summary")
            LoggingConfig.log_exception(logger, e, "get_data_split_summary")
            return {
                'training_seasons': [],
                'training_games': 0,
                'backtesting_season': '2025',
                'backtesting_games': 0,
                'data_split': []
            }
    
    def save_model(self, filepath: Optional[str] = None):
        """Ulo≈æ√≠ natr√©novan√Ω model s verz√≠ sch√©matu - ENHANCED"""
        try:
            if filepath is None:
                # === MIGRACE: Pou≈æij PATHS pro default filepath ===
                filepath = PATHS.get_model_file('elo_model_trained_2024', 'pkl')
            
            # Vytvo≈ô adres√°≈ô pokud neexistuje
            PATHS.trained_models.mkdir(parents=True, exist_ok=True)
            
            self.perf_logger.start_timer('save_model')
            
            model_data = {
                'team_ratings': self.team_ratings,
                'parameters': {
                    'initial_rating': self.initial_rating,
                    'k_factor': self.k_factor,
                    'home_advantage': self.home_advantage,
                    'season_regression': self.season_regression
                },
                'rating_history': self.rating_history,
                'trained_date': datetime.now().isoformat(),
                'schema_version': '2.1',  # ENHANCED: oznaƒçuje enhanced infrastructure
                'franchise_support': True,
                'enhanced_features': {  # NOV√â: enhanced infrastructure metadata
                    'per_component_logging': True,
                    'performance_monitoring': True,
                    'safe_file_handling': True,
                    'database_resilience': True
                }
            }
            
            # === MIGRACE: Safe model saving ===
            save_model_safe(model_data, 'elo_model_trained_2024', 'pkl')
            
            self.perf_logger.end_timer('save_model')
            
            logger.info(f"Enhanced model ulo≈æen do {filepath} (sch√©ma v2.1)")
            
        except Exception as e:
            logger.error("Failed to save model")
            LoggingConfig.log_exception(logger, e, "save_model")
            raise
        
    def load_model(self, filepath: Optional[str] = None):
        """Naƒçte natr√©novan√Ω model s kontrolou kompatibility sch√©matu - ENHANCED"""
        try:
            if filepath is None:
                filepath = PATHS.get_model_file('elo_model_trained_2024', 'pkl')
            
            self.perf_logger.start_timer('load_model')
            
            # === MIGRACE: Safe model loading ===
            model_data = load_model_safe('elo_model_trained_2024', 'pkl')
            
            # Kontrola verze sch√©matu
            schema_version = model_data.get('schema_version', '1.0')
            if schema_version == '1.0':
                logger.warning("Naƒç√≠t√°n√≠ star√©ho sch√©matu modelu - zva≈æte migraci")
            elif schema_version.startswith('2.1'):
                logger.info("Naƒç√≠t√°n√≠ enhanced modelu s plnou infrastructure podporou")
            
            self.team_ratings = model_data['team_ratings']
            self.rating_history = model_data['rating_history']
            
            # Naƒçti parametry
            params = model_data['parameters']
            self.initial_rating = params['initial_rating']
            self.k_factor = params['k_factor'] 
            self.home_advantage = params['home_advantage']
            self.season_regression = params['season_regression']
            
            self.perf_logger.end_timer('load_model')
            
            logger.info(f"Enhanced model naƒçten z {filepath} (sch√©ma v{schema_version})")
            
        except Exception as e:
            logger.error("Failed to load model")
            LoggingConfig.log_exception(logger, e, "load_model")
            raise

    def debug_team_mapping(self):
        """Debug metoda pro sledov√°n√≠ mapov√°n√≠ t√Ωm≈Ø - ENHANCED"""
        logger.info("üîç DEBUGGING TEAM MAPPING (ENHANCED):")
        
        try:
            # 1. Zkontroluj jak√© team IDs m√°me v self.team_ratings
            team_ids_sample = list(self.team_ratings.keys())[:10]
            logger.info(f"Team IDs in self.team_ratings: {team_ids_sample}...")
            
            # 2. Zkontroluj co je v datab√°zi
            query = """
            SELECT t.id, t.name, t.is_current, f.franchise_name
            FROM teams t
            JOIN franchises f ON t.franchise_id = f.id
            WHERE t.id IN (1,2,3,4,5,9,13,19,24)
            ORDER BY t.id
            """
            
            df = self.db_manager.execute_query_safe(
                query, "Debug team mapping query"
            )
            
            logger.info("UK√ÅZKOV√â T√ùMY Z DATAB√ÅZE:")
            for _, row in df.iterrows():
                current_flag = "‚úì" if row['is_current'] else "‚úó"
                logger.info(f"  ID {row['id']:2d}: {row['name']} ({row['franchise_name']}) {current_flag}")
        
            # 3. Test _get_team_names() metodu p≈ô√≠mo
            test_ids = [1, 9, 24]  # Top teams from log
            logger.info(f"Testov√°n√≠ _get_team_names() s ID: {test_ids}")
            result = self._get_team_names(test_ids)
            logger.info(f"V√Ωsledek: {result}")
            
        except Exception as e:
            logger.error("Debug team mapping failed")
            LoggingConfig.log_exception(logger, e, "debug_team_mapping")


def main():
    """
    Hlavn√≠ funkce pro tr√©nov√°n√≠ Enhanced Elo modelu
    KRITICK√â: Tr√©nuje pouze na datech do 2023/24, 2024/25 je pro backtesting
    """
    
    # === MIGRACE: Setup enhanced logging na zaƒç√°tku ===
    setup_logging(
        log_level='INFO',
        log_to_file=True,
        log_to_console=True,
        component_files=True  # Per-component log files
    )
    
    # Vytvo≈ô pot≈ôebn√© adres√°≈ôe
    PATHS.ensure_directories()
    
    logger.info("üèí Spu≈°tƒõn√≠ Enhanced Elo Rating System tr√©nov√°n√≠...")
    
    # === MIGRACE: Performance monitoring pro cel√Ω main ===
    main_perf = PerformanceLogger(logger)
    main_perf.start_timer('complete_training_process')
    
    try:
        # Inicializuj Enhanced Elo syst√©m s parametry ze settings
        logger.info("Inicializace Enhanced Elo Rating System...")
        elo = EloRatingSystem()  # Parametry se naƒçtou automaticky ze settings
        
        # Z√≠skej souhrn rozdƒõlen√≠ dat nejprve
        data_summary = elo.get_data_split_summary()
        logger.info("üìä SOUHRN ROZDƒöLEN√ç DAT:")
        logger.info(f"  Tr√©novac√≠ sez√≥ny: {data_summary['training_seasons']}")
        logger.info(f"  Tr√©novac√≠ z√°pasy: {data_summary['training_games']}")
        logger.info(f"  Backtesting sez√≥na: {data_summary['backtesting_season']}")
        logger.info(f"  Backtesting z√°pasy: {data_summary['backtesting_games']}")
        
        # Naƒçti TR√âNOVAC√ç data (sez√≥ny 2022-2024, vyj√≠maje 2024/25)
        logger.info("üìö Naƒç√≠t√°n√≠ TR√âNOVAC√çCH dat (do 2023/24)...")
        games_df = elo.load_historical_games(season_start='2022', season_end='2024')
        
        if games_df.empty:
            logger.error("Nenalezeny ≈æ√°dn√© tr√©novac√≠ z√°pasy. Ujistƒõte se, ≈æe data jsou importov√°na.")
            return
        
        # Validuj rozdƒõlen√≠ dat
        max_season = games_df['season'].max()
        try:
            max_season_int = int(max_season)
            if max_season_int > 2024:
                logger.error(f"KRITICK√Å CHYBA: Tr√©novac√≠ data obsahuj√≠ sez√≥nu {max_season}!")
                logger.error("Sez√≥na 2024/25 mus√≠ b√Ωt rezervov√°na pro backtesting!")
                return
        except (ValueError, TypeError):
            # Handle string season format
            if str(max_season) > '2024':
                logger.error(f"KRITICK√Å CHYBA: Tr√©novac√≠ data obsahuj√≠ sez√≥nu {max_season}!")
                logger.error("Sez√≥na 2024/25 mus√≠ b√Ωt rezervov√°na pro backtesting!")
                return
        
        logger.info(f"‚úÖ Tr√©novac√≠ data validov√°na: {len(games_df)} z√°pas≈Ø ze sez√≥n {games_df['season'].min()}-{max_season}")
        
        # Tr√©nuj model
        logger.info("üéØ Tr√©nov√°n√≠ Enhanced Elo rating≈Ø...")
        results = elo.train_on_historical_data(games_df, evaluate_predictions=True)
        
        # Zobraz v√Ωsledky
        logger.info("üéØ V√ùSLEDKY TR√âNINKU:")
        metrics = results['metrics']
        logger.info(f"  P≈ôesnost: {metrics.get('accuracy', 0):.3f}")
        logger.info(f"  Brier Score: {metrics.get('brier_score', 0):.3f}")
        logger.info(f"  Log Loss: {metrics.get('log_loss', 0):.3f}")
        logger.info(f"  Zpracovan√© z√°pasy: {results['games_processed']}")
        
        # Debug mapov√°n√≠ t√Ωm≈Ø
        logger.info("üîç DEBUGGING JMEN T√ùM≈Æ:")
        elo.debug_team_mapping()

        # Uka≈æ aktu√°ln√≠ ≈æeb≈ô√≠ƒçek t√Ωm≈Ø
        logger.info("üèÜ TOP 10 ENHANCED TEAM RATING≈Æ:")
        ratings_df = results['team_ratings']
        for _, team in ratings_df.head(10).iterrows():
            logger.info(f"  {team['rating_rank']:2d}. {team['team_name']:<25} {team['elo_rating']:7.1f}")
        
        # Arizona ‚Üí Utah p≈ôechod kontrola
        utah_teams = ratings_df[ratings_df['team_name'].str.contains('Utah', na=False)]
        if not utah_teams.empty:
            logger.info("ü¶£ UTAH P≈òECHOD OVƒö≈òEN:")
            for _, team in utah_teams.iterrows():
                logger.info(f"  {team['team_name']}: {team['elo_rating']:.1f} (po≈ôad√≠ {team['rating_rank']})")
        
        # === MIGRACE: Enhanced model saving ===
        logger.info("üíæ Ukl√°d√°n√≠ Enhanced modelu...")
        model_filepath = PATHS.trained_models / 'elo_model_enhanced_trained_2024.pkl'
        elo.save_model(model_filepath)
        
        # Ulo≈æ tak√© team ratings do JSON pro dal≈°√≠ pou≈æit√≠
        ratings_json_path = PATHS.trained_models / 'team_ratings_enhanced_current.json'
        ratings_dict = ratings_df.set_index('team_id')['elo_rating'].to_dict()
        write_json(ratings_dict, ratings_json_path)
        logger.info(f"Enhanced team ratings ulo≈æeny do {ratings_json_path}")
        
        # === MIGRACE: Enhanced training summary export ===
        training_summary = {
            'model_version': '2.1_enhanced',
            'trained_date': datetime.now().isoformat(),
            'training_data': {
                'seasons': f"{games_df['season'].min()}-{games_df['season'].max()}",
                'games_count': len(games_df),
                'teams_count': len(set(games_df['home_team_id']) | set(games_df['away_team_id']))
            },
            'model_parameters': {
                'initial_rating': elo.initial_rating,
                'k_factor': elo.k_factor,
                'home_advantage': elo.home_advantage,
                'season_regression': elo.season_regression
            },
            'performance_metrics': metrics,
            'enhanced_features': [
                'per_component_logging',
                'performance_monitoring', 
                'database_resilience',
                'safe_file_handling',
                'enhanced_error_handling'
            ]
        }
        
        summary_path = save_processed_data(
            pd.DataFrame([training_summary]), 
            'elo_training_summary_enhanced',
            index=False
        )
        logger.info(f"Enhanced training summary ulo≈æeno do {summary_path}")
        
        # Uka≈æ dostupnost backtesting dat
        logger.info("üìä DOSTUPN√Å BACKTESTING DATA:")
        backtesting_df = elo.load_backtesting_games('2025')
        completed_backtest = len(backtesting_df[backtesting_df['status'] == 'completed'])
        logger.info(f"  Celkem z√°pas≈Ø: {len(backtesting_df)}")
        logger.info(f"  Dokonƒçen√© (p≈ôipraven√© pro backtest): {completed_backtest}")
        logger.info(f"  Napl√°novan√© (budouc√≠ predikce): {len(backtesting_df) - completed_backtest}")
        
        main_perf.end_timer('complete_training_process')
        
        logger.info("üéâ Enhanced tr√©nov√°n√≠ modelu √∫spƒõ≈°nƒõ dokonƒçeno!")
        logger.info("üìã DAL≈†√ç KROKY:")
        logger.info("  1. Spus≈• backtesting na datech sez√≥ny 2024/25")
        logger.info("  2. Validuj v√Ωkon modelu na out-of-sample datech")
        logger.info("  3. Pokud √∫spƒõ≈°n√©, pokraƒçuj k implementaci live tradingu")
        logger.info("  4. Monitor performance v per-component log files:")
        logger.info(f"     - Models: {PATHS.logs}/models.log")
        logger.info(f"     - Database ops: {PATHS.logs}/database.log")
        logger.info(f"     - Main system: {PATHS.logs}/hockey_system.log")
        
    except Exception as e:
        main_perf.end_timer('complete_training_process')
        logger.error("‚ùå Enhanced tr√©nov√°n√≠ Elo modelu selhalo")
        LoggingConfig.log_exception(logger, e, "main")
        raise


if __name__ == "__main__":
    main()
